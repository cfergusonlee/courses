{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Tree Out of a Graph\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-10 at 3.31.26 PM.png\" />\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_edge: 744\n",
      "max_nodes: ('\"HUMAN TORCH/JOHNNY S\"', '\"THING/BENJAMIN J. GR\"')\n"
     ]
    }
   ],
   "source": [
    "marvel_bipartite = {}\n",
    "\n",
    "# Builds bipartite graph from data file\n",
    "# Keys are comic books and values are dicts of characters\n",
    "with open(\"data/marvel.tsv\") as f:\n",
    "    for line in f:\n",
    "        character, comic = line.split(\"\\t\")\n",
    "            \n",
    "        if comic not in marvel_bipartite:\n",
    "            marvel_bipartite[comic] = {character: 1}\n",
    "        else:\n",
    "            marvel_bipartite[comic][character] = 1\n",
    "\n",
    "marvel_graph = {}\n",
    "\n",
    "# Builds character to character graph from bipartite graph\n",
    "# Nodes are characters and edges are comics\n",
    "for comic, character_dict in marvel_bipartite.items():\n",
    "    for i in range(len(character_dict)-1):\n",
    "        for j in range(i + 1,len(character_dict)):\n",
    "            character_1, character_2 = sorted((list(character_dict.keys())[i], list(character_dict.keys())[j]))\n",
    "            if character_1 not in marvel_graph:\n",
    "                marvel_graph[character_1] = {}\n",
    "            if character_2 not in marvel_graph[character_1]:\n",
    "                marvel_graph[character_1][character_2] = 1\n",
    "            else:\n",
    "                marvel_graph[character_1][character_2] += 1\n",
    "                \n",
    "max_edge = 0\n",
    "max_nodes = ()\n",
    "\n",
    "# Finds highest weighted edge in graph\n",
    "for character_1, character_1_dict in marvel_graph.items():\n",
    "    for character_2, edge_value in character_1_dict.items():\n",
    "        if edge_value > max_edge:\n",
    "            max_edge = edge_value\n",
    "            max_nodes = (character_1, character_2)\n",
    "            \n",
    "print(\"max_edge:\", max_edge)\n",
    "print(\"max_nodes:\", max_nodes)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-11 at 11.00.35 AM.png\" />\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Social Networks\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-11 at 11.03.04 AM.png\" />\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-11 at 11.04.26 AM.png\" />\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Find the Shortest Path\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-11 at 11.42.27 AM.png\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dijkstra's Shortest Path Algorithm\n",
    "\n",
    "One way to conceptualize Dijkstra's is to use a breadth-first search while keeping track of the shortest path to each node in a dictionary. One key difference is that each time you come across a node that has already been visited, you need to compare that path length to the shortest length seen so far. If the path is shorter, you need to update the shortest path dictionary and traverse the connecting edges to see if there are any other paths that should be updated.\n",
    "\n",
    "One question to be answered is whether the lock-down step is necessary. If you're keeping track of the shortest so far, you may not need to do this.\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-12 at 3.05.20 PM.png\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dijksta's Using Ueaps\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-12 at 3.48.21 PM.png\" />\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-12 at 3.49.50 PM.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Pairs Shortest Paths\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-12 at 4.39.56 PM.png\" />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floyd-Warshall\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-12 at 4.43.13 PM.png\" />\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-12 at 4.47.57 PM.png\" />\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-12 at 6.10.22 PM.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomizing Clustering Coefficient\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-12 at 6.14.03 PM.png\" />\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-12 at 6.14.38 PM.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounds on the Estimate\n",
    "\n",
    "<img src=\"images/Screen Shot 2019-02-12 at 6.16.01 PM.png\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "int(math.ceil(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# The code below uses a linear\n",
    "# scan to find the unfinished node\n",
    "# with the smallest distance from\n",
    "# the source.\n",
    "#\n",
    "# Modify it to use a heap instead\n",
    "# \n",
    "\n",
    "import math\n",
    "\n",
    "def insert_node(heap, node, value):\n",
    "    # Inserts a node into the heap and returns the new heap\n",
    "    \n",
    "    heap.append((node, value))\n",
    "    heap = up_heapify(heap, len(heap) - 1)\n",
    "    \n",
    "    return heap\n",
    "    \n",
    "def get_parent(heap, index):\n",
    "    # Gets the parent of the current node\n",
    "    \n",
    "    if index == 0:\n",
    "        return index\n",
    "    \n",
    "    return int(math.ceil(index/2.0)-1)\n",
    "\n",
    "def get_left_child(heap, index):\n",
    "    # Returns the left child of the current node\n",
    "    \n",
    "    left_child = (index * 2) + 1\n",
    "    \n",
    "    if left_child > len(heap) - 1:\n",
    "        return None\n",
    "    \n",
    "    return left_child\n",
    "    \n",
    "def get_right_child(heap, index):\n",
    "    # Returns the right child of the current node\n",
    "    \n",
    "    right_child = (index * 2) + 2\n",
    "    \n",
    "    if right_child > len(heap) - 1:\n",
    "        return None\n",
    "    \n",
    "    return right_child\n",
    "    \n",
    "def down_heapify(heap, index):\n",
    "    # Bubbles the given node down the heap\n",
    "    # and returns the new heap\n",
    "    \n",
    "    left_child = get_left_child(heap, index)\n",
    "    right_child = get_right_child(heap, index)\n",
    "    \n",
    "    while left_child:\n",
    "        if not right_child:\n",
    "            heap[index], heap[left_child] = sorted([heap[index], heap[left_child]], key=lambda x: x[1])\n",
    "            return heap\n",
    "        elif heap[index][1] < min([heap[left_child], heap[right_child]], key=lambda x: x[1])[1]:\n",
    "            return heap\n",
    "        else:\n",
    "            if heap[left_child][1] < heap[right_child][1]:\n",
    "                heap[index], heap[left_child] = heap[left_child], heap[index]\n",
    "                index = left_child\n",
    "            else:\n",
    "                heap[index], heap[right_child] = heap[right_child], heap[index]\n",
    "                index = right_child\n",
    "        \n",
    "            left_child = get_left_child(heap, index)\n",
    "            right_child = get_right_child(heap, index)\n",
    "        \n",
    "    return heap\n",
    "\n",
    "def up_heapify(heap, index):\n",
    "    # Bubbles the given node up the heap\n",
    "    # and returns the new heap\n",
    "    \n",
    "    parent_index = get_parent(heap, index)\n",
    "    while index != parent_index and heap[parent_index][1] > heap[index][1]:\n",
    "        heap[parent_index], heap[index] = heap[index], heap[parent_index]\n",
    "        index = parent_index\n",
    "        parent_index = get_parent(heap, index)\n",
    "        \n",
    "    return heap\n",
    "    \n",
    "def update_heap(heap, index):\n",
    "    # Restructures the heap based on the newly inserted node\n",
    "    \n",
    "    heap = up_heapify(heap, index)\n",
    "    heap = down_heapify(heap, index)\n",
    "    \n",
    "    return heap\n",
    "    \n",
    "def remove_smallest_node(heap):\n",
    "    # Removes smallest node from heap and returns new heap\n",
    "    print(heap)\n",
    "    \n",
    "    heap[0], heap[-1] = heap[-1], heap[0]\n",
    "    min_node = heap.pop()\n",
    "    heap = down_heapify(heap, 0)\n",
    "    return min_node, heap    \n",
    "    \n",
    "\n",
    "def shortest_dist_node(dist):\n",
    "    best_node = 'undefined'\n",
    "    best_value = 1000000\n",
    "    for v in dist:\n",
    "        if dist[v] < best_value:\n",
    "            (best_node, best_value) = (v, dist[v])\n",
    "    return best_node\n",
    "\n",
    "def dijkstra(G,v):\n",
    "    # Convert dist_so_far from a dict to a list of tuples\n",
    "    # Each tuple contains a node and its distance\n",
    "    dist_so_far = [(v, 0)]\n",
    "    final_dist = {}\n",
    "    \n",
    "    while len(final_dist) < len(G):\n",
    "        #w = shortest_dist_node(dist_so_far)\n",
    "        w, dist_so_far = remove_smallest_node(dist_so_far)\n",
    "        # lock it down!\n",
    "        final_dist[w[0]] = w[1]\n",
    "        \n",
    "        for x in G[w[0]]:\n",
    "            if x not in final_dist:\n",
    "                dist_so_far_index = None\n",
    "                \n",
    "                for i in range(len(dist_so_far)):\n",
    "                    if dist_so_far[i][0] == x:\n",
    "                        dist_so_far_index = i\n",
    "                        \n",
    "                if not dist_so_far_index and dist_so_far_index != 0:\n",
    "                    dist_so_far = insert_node(dist_so_far, x, final_dist[w[0]] + G[w[0]][x])\n",
    "                elif final_dist[w[0]] + G[w[0]][x] < dist_so_far[dist_so_far_index][1]:\n",
    "                    dist_so_far[dist_so_far_index] = (dist_so_far[dist_so_far_index][0], final_dist[w[0]] + G[w[0]][x])\n",
    "                    dist_so_far = update_heap(dist_so_far, dist_so_far_index)\n",
    "    return final_dist\n",
    "\n",
    "############\n",
    "# \n",
    "# Test\n",
    "\n",
    "def make_link(G, node1, node2, w):\n",
    "    if node1 not in G:\n",
    "        G[node1] = {}\n",
    "    if node2 not in G[node1]:\n",
    "        (G[node1])[node2] = 0\n",
    "    (G[node1])[node2] += w\n",
    "    if node2 not in G:\n",
    "        G[node2] = {}\n",
    "    if node1 not in G[node2]:\n",
    "        (G[node2])[node1] = 0\n",
    "    (G[node2])[node1] += w\n",
    "    return G\n",
    "\n",
    "\n",
    "def test():\n",
    "    # shortcuts\n",
    "    (a,b,c,d,e,f,g) = ('A', 'B', 'C', 'D', 'E', 'F', 'G')\n",
    "    triples = ((a,c,3),(c,b,10),(a,b,15),(d,b,9),(a,d,4),(d,f,7),(d,e,3), \n",
    "               (e,g,1),(e,f,5),(f,g,2),(b,f,1))\n",
    "    G = {}\n",
    "    for (i,j,k) in triples:\n",
    "        make_link(G, i, j, k)\n",
    "\n",
    "    dist = dijkstra(G, a)\n",
    "    assert dist[g] == 8 #(a -> d -> e -> g)\n",
    "    assert dist[b] == 11 #(a -> d -> e -> g -> f -> b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 0)]\n",
      "('dist_so_far:', [])\n",
      "('dist_so_far:', [('C', 3)])\n",
      "('dist_so_far:', [('C', 3), ('B', 15)])\n",
      "[('C', 3), ('B', 15), ('D', 4)]\n",
      "[('D', 4), ('B', 13)]\n",
      "('dist_so_far:', [('B', 13)])\n",
      "('dist_so_far:', [('E', 7), ('B', 13)])\n",
      "[('E', 7), ('B', 13), ('F', 11)]\n",
      "('dist_so_far:', [('F', 11), ('B', 13)])\n",
      "[('G', 8), ('B', 13), ('F', 11)]\n",
      "[('F', 10), ('B', 13)]\n",
      "[('B', 11)]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# The code below uses a linear\n",
    "# scan to find the unfinished node\n",
    "# with the smallest distance from\n",
    "# the source.\n",
    "#\n",
    "# Modify it to use a heap instead\n",
    "# \n",
    "\n",
    "import math\n",
    "\n",
    "def insert_node(heap, index_dict, node, value):\n",
    "    # Inserts a node into the heap and returns the new heap\n",
    "    \n",
    "    heap.append((node, value))\n",
    "    index_dict[node] = len(heap) - 1\n",
    "    heap, index_dict = up_heapify(heap, index_dict, len(heap) - 1)\n",
    "    \n",
    "    return heap, index_dict\n",
    "    \n",
    "def get_parent(heap, index):\n",
    "    # Gets the parent of the current node\n",
    "    \n",
    "    if index == 0:\n",
    "        return index\n",
    "    \n",
    "    return int(math.ceil(index/2.0)-1)\n",
    "\n",
    "def get_left_child(heap, index):\n",
    "    # Returns the left child of the current node\n",
    "    \n",
    "    left_child = (index * 2) + 1\n",
    "    \n",
    "    if left_child > len(heap) - 1:\n",
    "        return None\n",
    "    \n",
    "    return left_child\n",
    "    \n",
    "def get_right_child(heap, index):\n",
    "    # Returns the right child of the current node\n",
    "    \n",
    "    right_child = (index * 2) + 2\n",
    "    \n",
    "    if right_child > len(heap) - 1:\n",
    "        return None\n",
    "    \n",
    "    return right_child\n",
    "\n",
    "def swap_heap_values(heap, index_dict, index_a, index_b):\n",
    "    a = heap[index_a][0]\n",
    "    b = heap[index_b][0]\n",
    "    index_dict[a] = index_b\n",
    "    index_dict[b] = index_a\n",
    "    heap[index_a], heap[index_b] = heap[index_b], heap[index_a]\n",
    "    \n",
    "    return heap, index_dict\n",
    "    \n",
    "def down_heapify(heap, index_dict, index):\n",
    "    # Bubbles the given node down the heap\n",
    "    # and returns the new heap\n",
    "    \n",
    "    left_child = get_left_child(heap, index)\n",
    "    right_child = get_right_child(heap, index)\n",
    "    \n",
    "    while left_child:\n",
    "        if not right_child:\n",
    "            if heap[left_child][1] < heap[index][1]:\n",
    "                heap, index_dict = swap_heap_values(heap, index_dict, index, left_child)\n",
    "            return heap, index_dict\n",
    "            #heap[index], heap[left_child] = sorted([heap[index], heap[left_child]], key=lambda x: x[1])\n",
    "            \n",
    "            #return heap\n",
    "        elif heap[index][1] < min([heap[left_child], heap[right_child]], key=lambda x: x[1])[1]:\n",
    "            return heap, index_dict\n",
    "        else:\n",
    "            if heap[left_child][1] < heap[right_child][1]:\n",
    "                heap, index_dict = swap_heap_values(heap, index_dict, index, left_child)\n",
    "                index = left_child\n",
    "                #heap[index], heap[left_child] = heap[left_child], heap[index]\n",
    "            else:\n",
    "                heap, index_dict = swap_heap_values(heap, index_dict, index, right_child)\n",
    "                index = right_child\n",
    "                #heap[index], heap[right_child] = heap[right_child], heap[index]\n",
    "        \n",
    "            left_child = get_left_child(heap, index)\n",
    "            right_child = get_right_child(heap, index)\n",
    "        \n",
    "    return heap, index_dict\n",
    "\n",
    "def up_heapify(heap, index_dict, index):\n",
    "    # Bubbles the given node up the heap\n",
    "    # and returns the new heap\n",
    "    \n",
    "    parent_index = get_parent(heap, index)\n",
    "    while index != parent_index and heap[parent_index][1] > heap[index][1]:\n",
    "        heap, index_dict = swap_heap_values(heap, index_dict, index, parent_index)\n",
    "        #heap[parent_index], heap[index] = heap[index], heap[parent_index]\n",
    "        index = parent_index\n",
    "        parent_index = get_parent(heap, index)\n",
    "        \n",
    "    return heap, index_dict\n",
    "    \n",
    "def update_heap(heap, index_dict, index):\n",
    "    # Restructures the heap based on the newly inserted node\n",
    "    \n",
    "    heap, index_dict = up_heapify(heap, index_dict, index)\n",
    "    heap, index_dict = down_heapify(heap, index_dict, index)\n",
    "    \n",
    "    return heap, index_dict\n",
    "    \n",
    "def remove_smallest_node(heap, index_dict):\n",
    "    # Removes smallest node from heap and returns new heap\n",
    "    print(heap)\n",
    "    heap, index_dict = swap_heap_values(heap, index_dict, 0, -1)\n",
    "    min_node = heap.pop()\n",
    "    del index_dict[min_node[0]]\n",
    "    heap, index_dict = down_heapify(heap, index_dict, 0)\n",
    "    return min_node, heap, index_dict    \n",
    "    \n",
    "\n",
    "def shortest_dist_node(dist):\n",
    "    best_node = 'undefined'\n",
    "    best_value = 1000000\n",
    "    for v in dist:\n",
    "        if dist[v] < best_value:\n",
    "            (best_node, best_value) = (v, dist[v])\n",
    "    return best_node\n",
    "\n",
    "def dijkstra(G,v):\n",
    "    # Convert dist_so_far from a dict to a list of tuples\n",
    "    # Each tuple contains a node and its distance\n",
    "    dist_so_far = [(v, 0)]\n",
    "    index_dict = {v: 0}\n",
    "    final_dist = {}\n",
    "    \n",
    "    while len(final_dist) < len(G):\n",
    "        #w = shortest_dist_node(dist_so_far)\n",
    "        w, dist_so_far, index_dict = remove_smallest_node(dist_so_far, index_dict)\n",
    "        \n",
    "        # lock it down!\n",
    "        final_dist[w[0]] = w[1]\n",
    "        \n",
    "        for x in G[w[0]]:\n",
    "            if x not in final_dist:\n",
    "                if x not in index_dict:\n",
    "                    print(\"dist_so_far:\", dist_so_far)\n",
    "                    dist_so_far, index_dict = insert_node(dist_so_far, index_dict, x, final_dist[w[0]] + G[w[0]][x])\n",
    "                elif final_dist[w[0]] + G[w[0]][x] < dist_so_far[index_dict[x]][1]:\n",
    "                    dist_so_far_index = index_dict[x]\n",
    "                    dist_so_far[dist_so_far_index] = (dist_so_far[dist_so_far_index][0], final_dist[w[0]] + G[w[0]][x])\n",
    "                    dist_so_far, index_dict = update_heap(dist_so_far, index_dict, dist_so_far_index)\n",
    "    return final_dist\n",
    "\n",
    "############\n",
    "# \n",
    "# Test\n",
    "\n",
    "def make_link(G, node1, node2, w):\n",
    "    if node1 not in G:\n",
    "        G[node1] = {}\n",
    "    if node2 not in G[node1]:\n",
    "        (G[node1])[node2] = 0\n",
    "    (G[node1])[node2] += w\n",
    "    if node2 not in G:\n",
    "        G[node2] = {}\n",
    "    if node1 not in G[node2]:\n",
    "        (G[node2])[node1] = 0\n",
    "    (G[node2])[node1] += w\n",
    "    return G\n",
    "\n",
    "\n",
    "def test():\n",
    "    # shortcuts\n",
    "    (a,b,c,d,e,f,g) = ('A', 'B', 'C', 'D', 'E', 'F', 'G')\n",
    "    triples = ((a,c,3),(c,b,10),(a,b,15),(d,b,9),(a,d,4),(d,f,7),(d,e,3), \n",
    "               (e,g,1),(e,f,5),(f,g,2),(b,f,1))\n",
    "    G = {}\n",
    "    for (i,j,k) in triples:\n",
    "        make_link(G, i, j, k)\n",
    "\n",
    "    dist = dijkstra(G, a)\n",
    "    assert dist[g] == 8 #(a -> d -> e -> g)\n",
    "    assert dist[b] == 11 #(a -> d -> e -> g -> f -> b)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 0)]\n",
      "('dist_so_far:', [])\n",
      "('dist_so_far:', [('C', 3)])\n",
      "('dist_so_far:', [('C', 3), ('B', 15)])\n",
      "[('C', 3), ('B', 15), ('D', 4)]\n",
      "('dist_so_far:', [('C', 3), ('B', 13)])\n",
      "('dist_so_far:', [('C', 3), ('B', 13), ('E', 7)])\n",
      "[('C', 3), ('F', 11), ('E', 7), ('B', 13)]\n",
      "[('C', 3), ('F', 11), ('E', 7)]\n",
      "('dist_so_far:', [('C', 3), ('F', 11)])\n",
      "[('C', 3), ('F', 11), ('G', 8)]\n",
      "[('C', 3), ('F', 10)]\n",
      "[('C', 3)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 13, 'C': 3, 'D': 4, 'E': 7, 'F': 10, 'G': 8}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a,b,c,d,e,f,g) = ('A', 'B', 'C', 'D', 'E', 'F', 'G')\n",
    "triples = ((a,c,3),(c,b,10),(a,b,15),(d,b,9),(a,d,4),(d,f,7),(d,e,3), \n",
    "           (e,g,1),(e,f,5),(f,g,2),(b,f,1))\n",
    "G = {}\n",
    "for (i,j,k) in triples:\n",
    "    make_link(G, i, j, k)\n",
    "\n",
    "dist = dijkstra(G, a)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# The code below uses a linear\n",
    "# scan to find the unfinished node\n",
    "# with the smallest distance from\n",
    "# the source.\n",
    "#\n",
    "# Modify it to use a heap instead\n",
    "# \n",
    "\n",
    "def shortest_dist_node(dist):\n",
    "    best_node = 'undefined'\n",
    "    best_value = 1000000\n",
    "    for v in dist:\n",
    "        if dist[v] < best_value:\n",
    "            (best_node, best_value) = (v, dist[v])\n",
    "    return best_node\n",
    "\n",
    "def dijkstra(G,v):\n",
    "    dist_so_far = {}\n",
    "    dist_so_far[v] = 0\n",
    "    final_dist = {}\n",
    "    while len(final_dist) < len(G):\n",
    "        w = shortest_dist_node(dist_so_far)\n",
    "        # lock it down!\n",
    "        final_dist[w] = dist_so_far[w]\n",
    "        del dist_so_far[w]\n",
    "        for x in G[w]:\n",
    "            if x not in final_dist:\n",
    "                if x not in dist_so_far:\n",
    "                    dist_so_far[x] = final_dist[w] + G[w][x]\n",
    "                elif final_dist[w] + G[w][x] < dist_so_far[x]:\n",
    "                    dist_so_far[x] = final_dist[w] + G[w][x]\n",
    "    return final_dist\n",
    "\n",
    "############\n",
    "# \n",
    "# Test\n",
    "\n",
    "def make_link(G, node1, node2, w):\n",
    "    if node1 not in G:\n",
    "        G[node1] = {}\n",
    "    if node2 not in G[node1]:\n",
    "        (G[node1])[node2] = 0\n",
    "    (G[node1])[node2] += w\n",
    "    if node2 not in G:\n",
    "        G[node2] = {}\n",
    "    if node1 not in G[node2]:\n",
    "        (G[node2])[node1] = 0\n",
    "    (G[node2])[node1] += w\n",
    "    return G\n",
    "\n",
    "\n",
    "def test():\n",
    "    # shortcuts\n",
    "    (a,b,c,d,e,f,g) = ('A', 'B', 'C', 'D', 'E', 'F', 'G')\n",
    "    triples = ((a,c,3),(c,b,10),(a,b,15),(d,b,9),(a,d,4),(d,f,7),(d,e,3), \n",
    "               (e,g,1),(e,f,5),(f,g,2),(b,f,1))\n",
    "    G = {}\n",
    "    for (i,j,k) in triples:\n",
    "        make_link(G, i, j, k)\n",
    "\n",
    "    dist = dijkstra(G, a)\n",
    "    assert dist[g] == 8 #(a -> d -> e -> g)\n",
    "    assert dist[b] == 11 #(a -> d -> e -> g -> f -> b)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>comic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24-HOUR MAN/EMMANUEL</td>\n",
       "      <td>AA2 35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-D MAN/CHARLES CHAN</td>\n",
       "      <td>AVF 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-D MAN/CHARLES CHAN</td>\n",
       "      <td>AVF 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-D MAN/CHARLES CHAN</td>\n",
       "      <td>COC 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-D MAN/CHARLES CHAN</td>\n",
       "      <td>H2 251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              character   comic\n",
       "0  24-HOUR MAN/EMMANUEL  AA2 35\n",
       "1  3-D MAN/CHARLES CHAN   AVF 4\n",
       "2  3-D MAN/CHARLES CHAN   AVF 5\n",
       "3  3-D MAN/CHARLES CHAN   COC 1\n",
       "4  3-D MAN/CHARLES CHAN  H2 251"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/marvel.tsv\", sep=\"\\t\", header=None, names=[\"character\", \"comic\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('No co_characters for:', 'BERSERKER II')\n",
      "('No co_characters for:', 'BLARE/')\n",
      "('No co_characters for:', 'CALLAHAN, DANNY')\n",
      "('No co_characters for:', 'CLUMSY FOULUP')\n",
      "('No co_characters for:', 'DEATHCHARGE')\n",
      "('No co_characters for:', 'FENRIS')\n",
      "('No co_characters for:', 'GERVASE, LADY ALYSSA')\n",
      "('No co_characters for:', 'GIURESCU, RADU')\n",
      "('No co_characters for:', 'JOHNSON, LYNDON BAIN')\n",
      "('No co_characters for:', 'KULL')\n",
      "('No co_characters for:', 'LUNATIK II')\n",
      "('No co_characters for:', 'MARVEL BOY II/MARTIN')\n",
      "('No co_characters for:', 'RANDAK')\n",
      "('No co_characters for:', 'RED WOLF II')\n",
      "('No co_characters for:', 'RUNE')\n",
      "('No co_characters for:', 'SEA LEOPARD')\n",
      "('No co_characters for:', 'SHARKSKIN')\n",
      "('No co_characters for:', 'ZANTOR')\n"
     ]
    }
   ],
   "source": [
    "def create_character_graph(df):\n",
    "    \n",
    "    character_graph = {}\n",
    "    \n",
    "    for character in sorted(pd.unique(df.character)):\n",
    "\n",
    "        comics = df.loc[df.character == character, \"comic\"].tolist()\n",
    "        co_characters = df.loc[(df.comic.isin(comics)) & (df.character != character), \"character\"].tolist()\n",
    "\n",
    "        co_character_counts = dict(Counter(co_characters))\n",
    "        for co_character, count in co_character_counts.items():\n",
    "            co_character_counts[co_character] = 1.0 / count\n",
    "\n",
    "        if len(co_characters) == 0: \n",
    "            print(\"No co_characters for:\", character)\n",
    "            continue\n",
    "\n",
    "        character_graph[character] = co_character_counts\n",
    "        \n",
    "    return character_graph\n",
    "\n",
    "character_graph = create_character_graph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(graph, node):\n",
    "    \n",
    "    simple_paths = {node: {'hops': 0, 'weight': 0}}\n",
    "    queue = [node]\n",
    "    \n",
    "    while len(queue) > 0:\n",
    "        current_node = queue[0]\n",
    "        del queue[0]\n",
    "        \n",
    "        for co_character in graph[current_node]:\n",
    "            if co_character not in simple_paths:\n",
    "                queue.append(co_character)\n",
    "                simple_paths[co_character] = {\n",
    "                    'weight': simple_paths[current_node]['weight'] + graph[current_node][co_character],\n",
    "                    'hops': simple_paths[current_node]['hops'] + 1\n",
    "                }\n",
    "                    \n",
    "                \n",
    "    return simple_paths\n",
    "\n",
    "characters_of_interest = [\n",
    "    'SPIDER-MAN/PETER PAR',\n",
    "    'GREEN GOBLIN/NORMAN ',\n",
    "    'WOLVERINE/LOGAN ',\n",
    "    'PROFESSOR X/CHARLES ',\n",
    "    'CAPTAIN AMERICA'\n",
    "]\n",
    "\n",
    "character_simple_paths = {}\n",
    "\n",
    "for character in characters_of_interest:\n",
    "    character_simple_paths[character] = bfs(character_graph, character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weighted_count:', 4408)\n",
      "('weighted_count:', 10183)\n",
      "('weighted_count:', 15582)\n",
      "('weighted_count:', 19747)\n",
      "('weighted_count:', 23289)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23289"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_smallest(dist_so_far):\n",
    "    smallest_node = ''\n",
    "    smallest_weight = 1000000\n",
    "    for node, value in dist_so_far.items():\n",
    "        if value['weight'] < smallest_weight: \n",
    "            smallest_node = node\n",
    "            smallest_weight = value['weight']\n",
    "            \n",
    "    return smallest_node\n",
    "\n",
    "def dijkstra(character_graph, simple_paths, node):\n",
    "    \n",
    "    final_distances = {}\n",
    "    dist_so_far = {node: {'hops': 0, 'weight': 0}}\n",
    "    current_node = node\n",
    "    \n",
    "    while len(final_distances) < len(simple_paths):\n",
    "        w = get_smallest(dist_so_far)\n",
    "        final_distances[w] = dist_so_far[w]\n",
    "        del dist_so_far[w]\n",
    "        \n",
    "        for co_character in character_graph[w]:\n",
    "            if co_character not in final_distances:\n",
    "                new_hops = final_distances[w]['hops'] + 1\n",
    "                new_weight = final_distances[w]['weight'] + character_graph[w][co_character]\n",
    "                if co_character not in dist_so_far:\n",
    "                    dist_so_far[co_character] = {'hops': new_hops, 'weight': new_weight}\n",
    "                elif new_weight < dist_so_far[co_character]['weight']:\n",
    "                    dist_so_far[co_character] = {'hops': new_hops, 'weight': new_weight}        \n",
    "    \n",
    "    return final_distances\n",
    "    \n",
    "weighted_count = 0\n",
    "    \n",
    "for character, simple_paths in character_simple_paths.items():\n",
    "    \n",
    "    weighted_paths = dijkstra(character_graph, simple_paths, character)\n",
    "    \n",
    "    weighted_count += sum([weighted_paths[c]['hops'] != simple_paths[c]['hops'] for c in simple_paths])\n",
    "    print(\"weighted_count:\", weighted_count)\n",
    "    \n",
    "    \n",
    "weighted_count          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>movie</th>\n",
       "      <th>year</th>\n",
       "      <th>obscurity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [actor, movie, year, obscurity]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Another way of thinking of a path in the Kevin Bacon game \n",
    "# is not about finding *short* paths, but by finding paths \n",
    "# that don’t use obscure movies.  We will give you a \n",
    "# list of movies along with their obscureness score.  \n",
    "#\n",
    "# For this assignment, we'll approximate obscurity \n",
    "# based on the multiplicative inverse of the amount of \n",
    "# money the movie made.  Though, its not really important where\n",
    "# the obscurity score came from.\n",
    "#\n",
    "# Use the the imdb-1.tsv and imdb-weights.tsv files to find\n",
    "# the obscurity of the “least obscure” \n",
    "# path from a given actor to another.  \n",
    "# The obscurity of a path is the maximum obscurity of \n",
    "# any of the movies used along the path.\n",
    "#\n",
    "# You will have to do the processing in your local environment\n",
    "# and then copy in your answer.\n",
    "#\n",
    "# Hint: A variation of Dijkstra can be used to solve this problem.\n",
    "#\n",
    "\n",
    "# Change the `None` values in this dictionary to be the obscurity score\n",
    "# of the least obscure path between the two actors\n",
    "answer = {(u'Boone Junior, Mark', u'Del Toro, Benicio'): None,\n",
    "          (u'Braine, Richard', u'Coogan, Will'): None,\n",
    "          (u'Byrne, Michael (I)', u'Quinn, Al (I)'): None,\n",
    "          (u'Cartwright, Veronica', u'Edelstein, Lisa'): None,\n",
    "          (u'Curry, Jon (II)', u'Wise, Ray (I)'): None,\n",
    "          (u'Di Benedetto, John', u'Hallgrey, Johnathan'): None,\n",
    "          (u'Hochendoner, Jeff', u'Cross, Kendall'): None,\n",
    "          (u'Izquierdo, Ty', u'Kimball, Donna'): None,\n",
    "          (u'Jace, Michael', u'Snell, Don'): None,\n",
    "          (u'James, Charity', u'Tuerpe, Paul'): None,\n",
    "          (u'Kay, Dominic Scott', u'Cathey, Reg E.'): None,\n",
    "          (u'McCabe, Richard', u'Washington, Denzel'): None,\n",
    "          (u'Reid, Kevin (I)', u'Affleck, Rab'): None,\n",
    "          (u'Reid, R.D.', u'Boston, David (IV)'): None,\n",
    "          (u'Restivo, Steve', u'Preston, Carrie (I)'): None,\n",
    "          (u'Rodriguez, Ramon (II)', u'Mulrooney, Kelsey'): None,\n",
    "          (u'Rooker, Michael (I)', u'Grady, Kevin (I)'): None,\n",
    "          (u'Ruscoe, Alan', u'Thornton, Cooper'): None,\n",
    "          (u'Sloan, Tina', u'Dever, James D.'): None,\n",
    "          (u'Wasserman, Jerry', u'Sizemore, Tom'): None}\n",
    "\n",
    "# Here are some test cases.\n",
    "# For example, the obscurity score of the least obscure path\n",
    "# between 'Ali, Tony' and 'Allen, Woody' is 0.5657\n",
    "test = {(u'Ali, Tony', u'Allen, Woody'): 0.5657,\n",
    "        (u'Auberjonois, Rene', u'MacInnes, Angus'): 0.0814,\n",
    "        (u'Avery, Shondrella', u'Dorsey, Kimberly (I)'): 0.7837,\n",
    "        (u'Bollo, Lou', u'Jeremy, Ron'): 0.4763,\n",
    "        (u'Byrne, P.J.', u'Clarke, Larry'): 0.109,\n",
    "        (u'Couturier, Sandra-Jessica', u'Jean-Louis, Jimmy'): 0.3649,\n",
    "        (u'Crawford, Eve (I)', u'Cutler, Tom'): 0.2052,\n",
    "        (u'Flemyng, Jason', u'Newman, Laraine'): 0.139,\n",
    "        (u'French, Dawn', u'Smallwood, Tucker'): 0.2979,\n",
    "        (u'Gunton, Bob', u'Nagra, Joti'): 0.2136,\n",
    "        (u'Hoffman, Jake (I)', u'Shook, Carol'): 0.6073,\n",
    "        (u'Kamiki, Ry\\xfbnosuke', u'Thor, Cameron'): 0.3644,\n",
    "        (u'Roache, Linus', u'Dreyfuss, Richard'): 0.6731,\n",
    "        (u'Sanchez, Phillip (I)', u'Wiest, Dianne'): 0.5083,\n",
    "        (u'Sheppard, William Morgan', u'Crook, Mackenzie'): 0.0849,\n",
    "        (u'Stan, Sebastian', u'Malahide, Patrick'): 0.2857,\n",
    "        (u'Tessiero, Michael A.', u'Molen, Gerald R.'): 0.2056,\n",
    "        (u'Thomas, Ken (I)', u'Bell, Jamie (I)'): 0.3941,\n",
    "        (u'Thompson, Sophie (I)', u'Foley, Dave (I)'): 0.1095,\n",
    "        (u'Tzur, Mira', u'Heston, Charlton'): 0.3642}\n",
    "\n",
    "movie_actor_df = pd.read_csv(\"data/imdb.tsv\", sep=\"\\t\", header=None, names=[\"actor\", \"movie\", \"year\"])\n",
    "movie_obscurity_df = pd.read_csv(\"data/imdb_obscurity.tsv\", sep=\"\\t\", header=None, names=[\"movie\", \"year\", \"obscurity\"])\n",
    "\n",
    "movie_df = pd.merge(movie_actor_df, movie_obscurity_df, on=[\"movie\", \"year\"], how=\"left\")\n",
    "movie_df[movie_df.obscurity.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_movie_graph(df):\n",
    "    movie_graph = {}\n",
    "\n",
    "    for actor in sorted(pd.unique(df.actor)):\n",
    "\n",
    "        movies_years = df.loc[df.actor == actor, [\"movie\", \"year\"]]\n",
    "        movies = movies_years[\"movie\"].tolist()\n",
    "        years = movies_years[\"year\"].tolist()\n",
    "        costar_df = pd.DataFrame({\"actor\": [], \"obscurity\": []})\n",
    "\n",
    "        for movie, year in zip(movies, years):\n",
    "            costar_df = costar_df.append(df.loc[(df.actor != actor) & (df.year == year) & (df.movie == movie), [\"actor\", \"obscurity\"]])\n",
    "\n",
    "        costar_dict = costar_df.sort_values([\"actor\", \"obscurity\"]).groupby(\"actor\").first()[\"obscurity\"].to_dict()\n",
    "\n",
    "        movie_graph[actor] = costar_dict\n",
    "        \n",
    "    return movie_graph\n",
    "\n",
    "movie_graph = create_movie_graph(movie_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_smallest_node(weights_so_far):\n",
    "    smallest_weight = 1000000\n",
    "    smallest_node = \"\"\n",
    "    \n",
    "    for node, weight in weights_so_far.items():\n",
    "        if weight < smallest_weight:\n",
    "            smallest_weight = weight\n",
    "            smallest_node = node\n",
    "            \n",
    "    return smallest_node\n",
    "\n",
    "def dijkstra_search(start_node, end_node, graph):\n",
    "    paths_so_far = {start_node: 0}\n",
    "    final_paths = {}    \n",
    "    \n",
    "    while end_node not in final_paths:\n",
    "        w = get_smallest_node(paths_so_far)\n",
    "        final_paths[w] = paths_so_far[w]\n",
    "        #print(\"final_paths length:\", len(final_paths))\n",
    "        #if len(final_paths) % 300 == 0: print(\"final_paths length:\", len(final_paths))\n",
    "        del paths_so_far[w]\n",
    "        \n",
    "        for neighbor in graph[w]:\n",
    "            if neighbor not in final_paths:\n",
    "                new_path = max([final_paths[w], graph[w][neighbor]])\n",
    "                if neighbor not in paths_so_far or new_path < paths_so_far[neighbor]:\n",
    "                    paths_so_far[neighbor] = new_path\n",
    "        \n",
    "    return final_paths\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer[('Boone Junior, Mark', 'Del Toro, Benicio')]: 0.2979\n",
      "answer[('Braine, Richard', 'Coogan, Will')]: 1.1345\n",
      "answer[('Byrne, Michael (I)', 'Quinn, Al (I)')]: 0.1736\n",
      "answer[('Cartwright, Veronica', 'Edelstein, Lisa')]: 0.7161\n",
      "answer[('Curry, Jon (II)', 'Wise, Ray (I)')]: 0.2872\n",
      "answer[('Di Benedetto, John', 'Hallgrey, Johnathan')]: 0.8361\n",
      "answer[('Hochendoner, Jeff', 'Cross, Kendall')]: 0.6228\n",
      "answer[('Izquierdo, Ty', 'Kimball, Donna')]: 0.2616\n",
      "answer[('Jace, Michael', 'Snell, Don')]: 0.6758\n",
      "answer[('James, Charity', 'Tuerpe, Paul')]: 0.5079\n",
      "answer[('Kay, Dominic Scott', 'Cathey, Reg E.')]: 0.2184\n",
      "answer[('McCabe, Richard', 'Washington, Denzel')]: 0.4031\n",
      "answer[('Reid, Kevin (I)', 'Affleck, Rab')]: 0.5147\n",
      "answer[('Reid, R.D.', 'Boston, David (IV)')]: 0.5768\n",
      "answer[('Restivo, Steve', 'Preston, Carrie (I)')]: 0.3628\n",
      "answer[('Rodriguez, Ramon (II)', 'Mulrooney, Kelsey')]: 0.2394\n",
      "answer[('Rooker, Michael (I)', 'Grady, Kevin (I)')]: 0.3693\n",
      "answer[('Ruscoe, Alan', 'Thornton, Cooper')]: 0.4072\n",
      "answer[('Sloan, Tina', 'Dever, James D.')]: 0.5636\n",
      "answer[('Wasserman, Jerry', 'Sizemore, Tom')]: 0.1999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('Boone Junior, Mark', 'Del Toro, Benicio'): 0.2979,\n",
       " ('Braine, Richard', 'Coogan, Will'): 1.1345,\n",
       " ('Byrne, Michael (I)', 'Quinn, Al (I)'): 0.1736,\n",
       " ('Cartwright, Veronica', 'Edelstein, Lisa'): 0.7161,\n",
       " ('Curry, Jon (II)', 'Wise, Ray (I)'): 0.2872,\n",
       " ('Di Benedetto, John', 'Hallgrey, Johnathan'): 0.8361,\n",
       " ('Hochendoner, Jeff', 'Cross, Kendall'): 0.6228,\n",
       " ('Izquierdo, Ty', 'Kimball, Donna'): 0.2616,\n",
       " ('Jace, Michael', 'Snell, Don'): 0.6758,\n",
       " ('James, Charity', 'Tuerpe, Paul'): 0.5079,\n",
       " ('Kay, Dominic Scott', 'Cathey, Reg E.'): 0.2184,\n",
       " ('McCabe, Richard', 'Washington, Denzel'): 0.4031,\n",
       " ('Reid, Kevin (I)', 'Affleck, Rab'): 0.5147,\n",
       " ('Reid, R.D.', 'Boston, David (IV)'): 0.5768,\n",
       " ('Restivo, Steve', 'Preston, Carrie (I)'): 0.3628,\n",
       " ('Rodriguez, Ramon (II)', 'Mulrooney, Kelsey'): 0.2394,\n",
       " ('Rooker, Michael (I)', 'Grady, Kevin (I)'): 0.3693,\n",
       " ('Ruscoe, Alan', 'Thornton, Cooper'): 0.4072,\n",
       " ('Sloan, Tina', 'Dever, James D.'): 0.5636,\n",
       " ('Wasserman, Jerry', 'Sizemore, Tom'): 0.1999}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tup in answer:\n",
    "    start_node, end_node = tup\n",
    "    smallest_paths = dijkstra_search(start_node, end_node, movie_graph)\n",
    "    answer[tup] = smallest_paths[end_node]\n",
    "    print(\"answer[{}]:\".format(tup), answer[tup])\n",
    "    \n",
    "answer    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = {(u'Ali, Tony', u'Allen, Woody'): 0.5657,\n",
    "        (u'Auberjonois, Rene', u'MacInnes, Angus'): 0.0814,\n",
    "        (u'Avery, Shondrella', u'Dorsey, Kimberly (I)'): 0.7837,\n",
    "        (u'Bollo, Lou', u'Jeremy, Ron'): 0.4763,\n",
    "        (u'Byrne, P.J.', u'Clarke, Larry'): 0.109,\n",
    "        (u'Couturier, Sandra-Jessica', u'Jean-Louis, Jimmy'): 0.3649,\n",
    "        (u'Crawford, Eve (I)', u'Cutler, Tom'): 0.2052,\n",
    "        (u'Flemyng, Jason', u'Newman, Laraine'): 0.139,\n",
    "        (u'French, Dawn', u'Smallwood, Tucker'): 0.2979,\n",
    "        (u'Gunton, Bob', u'Nagra, Joti'): 0.2136,\n",
    "        (u'Hoffman, Jake (I)', u'Shook, Carol'): 0.6073,\n",
    "        (u'Kamiki, Ry\\xfbnosuke', u'Thor, Cameron'): 0.3644,\n",
    "        (u'Roache, Linus', u'Dreyfuss, Richard'): 0.6731,\n",
    "        (u'Sanchez, Phillip (I)', u'Wiest, Dianne'): 0.5083,\n",
    "        (u'Sheppard, William Morgan', u'Crook, Mackenzie'): 0.0849,\n",
    "        (u'Stan, Sebastian', u'Malahide, Patrick'): 0.2857,\n",
    "        (u'Tessiero, Michael A.', u'Molen, Gerald R.'): 0.2056,\n",
    "        (u'Thomas, Ken (I)', u'Bell, Jamie (I)'): 0.3941,\n",
    "        (u'Thompson, Sophie (I)', u'Foley, Dave (I)'): 0.1095,\n",
    "        (u'Tzur, Mira', u'Heston, Charlton'): 0.3642}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "expected answer[('Ali, Tony', 'Allen, Woody')]: 0.5657\n",
      "answer[('Ali, Tony', 'Allen, Woody')]: 0.5657\n",
      "True\n",
      "expected answer[('Auberjonois, Rene', 'MacInnes, Angus')]: 0.0814\n",
      "answer[('Auberjonois, Rene', 'MacInnes, Angus')]: 0.0814\n",
      "True\n",
      "expected answer[('Avery, Shondrella', 'Dorsey, Kimberly (I)')]: 0.7837\n",
      "answer[('Avery, Shondrella', 'Dorsey, Kimberly (I)')]: 0.7837\n",
      "True\n",
      "expected answer[('Bollo, Lou', 'Jeremy, Ron')]: 0.4763\n",
      "answer[('Bollo, Lou', 'Jeremy, Ron')]: 0.4763\n",
      "True\n",
      "expected answer[('Byrne, P.J.', 'Clarke, Larry')]: 0.109\n",
      "answer[('Byrne, P.J.', 'Clarke, Larry')]: 0.109\n",
      "True\n",
      "expected answer[('Couturier, Sandra-Jessica', 'Jean-Louis, Jimmy')]: 0.3649\n",
      "answer[('Couturier, Sandra-Jessica', 'Jean-Louis, Jimmy')]: 0.3649\n",
      "True\n",
      "expected answer[('Crawford, Eve (I)', 'Cutler, Tom')]: 0.2052\n",
      "answer[('Crawford, Eve (I)', 'Cutler, Tom')]: 0.2052\n",
      "True\n",
      "expected answer[('Flemyng, Jason', 'Newman, Laraine')]: 0.139\n",
      "answer[('Flemyng, Jason', 'Newman, Laraine')]: 0.139\n",
      "True\n",
      "expected answer[('French, Dawn', 'Smallwood, Tucker')]: 0.2979\n",
      "answer[('French, Dawn', 'Smallwood, Tucker')]: 0.2979\n",
      "True\n",
      "expected answer[('Gunton, Bob', 'Nagra, Joti')]: 0.2136\n",
      "answer[('Gunton, Bob', 'Nagra, Joti')]: 0.2136\n",
      "True\n",
      "expected answer[('Hoffman, Jake (I)', 'Shook, Carol')]: 0.6073\n",
      "answer[('Hoffman, Jake (I)', 'Shook, Carol')]: 0.6073\n",
      "True\n",
      "expected answer[('Kamiki, Ryûnosuke', 'Thor, Cameron')]: 0.3644\n",
      "answer[('Kamiki, Ryûnosuke', 'Thor, Cameron')]: 0.3644\n",
      "True\n",
      "expected answer[('Roache, Linus', 'Dreyfuss, Richard')]: 0.6731\n",
      "answer[('Roache, Linus', 'Dreyfuss, Richard')]: 0.6731\n",
      "True\n",
      "expected answer[('Sanchez, Phillip (I)', 'Wiest, Dianne')]: 0.5083\n",
      "answer[('Sanchez, Phillip (I)', 'Wiest, Dianne')]: 0.5083\n",
      "True\n",
      "expected answer[('Sheppard, William Morgan', 'Crook, Mackenzie')]: 0.0849\n",
      "answer[('Sheppard, William Morgan', 'Crook, Mackenzie')]: 0.0849\n",
      "True\n",
      "expected answer[('Stan, Sebastian', 'Malahide, Patrick')]: 0.2857\n",
      "answer[('Stan, Sebastian', 'Malahide, Patrick')]: 0.2857\n",
      "True\n",
      "expected answer[('Tessiero, Michael A.', 'Molen, Gerald R.')]: 0.2056\n",
      "answer[('Tessiero, Michael A.', 'Molen, Gerald R.')]: 0.2056\n",
      "True\n",
      "expected answer[('Thomas, Ken (I)', 'Bell, Jamie (I)')]: 0.3941\n",
      "answer[('Thomas, Ken (I)', 'Bell, Jamie (I)')]: 0.3941\n",
      "True\n",
      "expected answer[('Thompson, Sophie (I)', 'Foley, Dave (I)')]: 0.1095\n",
      "answer[('Thompson, Sophie (I)', 'Foley, Dave (I)')]: 0.1095\n",
      "True\n",
      "expected answer[('Tzur, Mira', 'Heston, Charlton')]: 0.3642\n",
      "answer[('Tzur, Mira', 'Heston, Charlton')]: 0.3642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('Ali, Tony', 'Allen, Woody'): 0.5657,\n",
       " ('Auberjonois, Rene', 'MacInnes, Angus'): 0.0814,\n",
       " ('Avery, Shondrella', 'Dorsey, Kimberly (I)'): 0.7837,\n",
       " ('Bollo, Lou', 'Jeremy, Ron'): 0.4763,\n",
       " ('Byrne, P.J.', 'Clarke, Larry'): 0.109,\n",
       " ('Couturier, Sandra-Jessica', 'Jean-Louis, Jimmy'): 0.3649,\n",
       " ('Crawford, Eve (I)', 'Cutler, Tom'): 0.2052,\n",
       " ('Flemyng, Jason', 'Newman, Laraine'): 0.139,\n",
       " ('French, Dawn', 'Smallwood, Tucker'): 0.2979,\n",
       " ('Gunton, Bob', 'Nagra, Joti'): 0.2136,\n",
       " ('Hoffman, Jake (I)', 'Shook, Carol'): 0.6073,\n",
       " ('Kamiki, Ryûnosuke', 'Thor, Cameron'): 0.3644,\n",
       " ('Roache, Linus', 'Dreyfuss, Richard'): 0.6731,\n",
       " ('Sanchez, Phillip (I)', 'Wiest, Dianne'): 0.5083,\n",
       " ('Sheppard, William Morgan', 'Crook, Mackenzie'): 0.0849,\n",
       " ('Stan, Sebastian', 'Malahide, Patrick'): 0.2857,\n",
       " ('Tessiero, Michael A.', 'Molen, Gerald R.'): 0.2056,\n",
       " ('Thomas, Ken (I)', 'Bell, Jamie (I)'): 0.3941,\n",
       " ('Thompson, Sophie (I)', 'Foley, Dave (I)'): 0.1095,\n",
       " ('Tzur, Mira', 'Heston, Charlton'): 0.3642}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for tup in test:\n",
    "    start_node, end_node = tup\n",
    "    smallest_paths = dijkstra_search(start_node, end_node, movie_graph)\n",
    "    print(test[tup] == smallest_paths[end_node])\n",
    "    print(\"expected answer[{}]:\".format(tup), test[tup])\n",
    "    print(\"answer[{}]:\".format(tup), smallest_paths[end_node])    \n",
    "    \n",
    "test    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
